{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic_modified_dataset.csv', index_col = 'PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Title  \\\n",
       "PassengerId                                                              \n",
       "1                 3    0  22.0      1      0   7.2500         0      0   \n",
       "2                 1    1  38.0      1      0  71.2833         1      1   \n",
       "3                 3    1  26.0      0      0   7.9250         0      2   \n",
       "4                 1    1  35.0      1      0  53.1000         0      1   \n",
       "5                 3    0  35.0      0      0   8.0500         0      0   \n",
       "...             ...  ...   ...    ...    ...      ...       ...    ...   \n",
       "887               2    0  27.0      0      0  13.0000         0      5   \n",
       "888               1    1  19.0      0      0  30.0000         0      2   \n",
       "889               3    1  28.0      1      2  23.4500         0      2   \n",
       "890               1    0  26.0      0      0  30.0000         1      0   \n",
       "891               3    0  32.0      0      0   7.7500         2      0   \n",
       "\n",
       "             Survived  \n",
       "PassengerId            \n",
       "1                   0  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                   0  \n",
       "...               ...  \n",
       "887                 0  \n",
       "888                 1  \n",
       "889                 0  \n",
       "890                 1  \n",
       "891                 0  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic_modified_dataset.csv\", index_col = \"PassengerId\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 891 entries, 1 to 891\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    891 non-null    int64  \n",
      " 1   Sex       891 non-null    int64  \n",
      " 2   Age       891 non-null    float64\n",
      " 3   SibSp     891 non-null    int64  \n",
      " 4   Parch     891 non-null    int64  \n",
      " 5   Fare      891 non-null    float64\n",
      " 6   Embarked  891 non-null    int64  \n",
      " 7   Title     891 non-null    int64  \n",
      " 8   Survived  891 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 69.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_arr = df.to_numpy().astype(np.float64)\n",
    "X, y = dataset_arr[:, :-1], dataset_arr[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = np.ones((X.shape[0], 1))\n",
    "\n",
    "X_b = np.concatenate([intercept, X], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "test_size = 0.125\n",
    "random_state = 2\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_b, y, test_size = val_size, shuffle = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = test_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train[:, 1:] = normalizer.fit_transform(X_train[:, 1:])\n",
    "X_val[:, 1:] = normalizer.transform(X_val[:, 1:])\n",
    "X_test[:, 1:] = normalizer.transform(X_test[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def predict(X, theta):\n",
    "    z = np.dot(X, theta)\n",
    "    y_hat = sigmoid(z)\n",
    "    return y_hat\n",
    "\n",
    "def compute_loss(y, y_hat):\n",
    "    y_hat = np.clip(y_hat, 1e-7, 1- 1e-7)\n",
    "    return (-y*np.log(y_hat) - (1-y)*np.log(1-y_hat)).mean()\n",
    "\n",
    "def compute_gradient(X, y, y_hat):\n",
    "    return np.dot(X.T, (y_hat - y))/y.size()\n",
    "\n",
    "def update_theta(theta, gradient, lr):\n",
    "    return theta - lr*gradient\n",
    "\n",
    "def compute_accuracy(X, y, theta):\n",
    "    y_hat = predict(X, theta).round()\n",
    "    accuracy = (y_hat == y).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "np.random.seed(random_state)\n",
    "theta = np.random.uniform(size=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (891,8) and (9,) not aligned: 8 (dim 1) != 9 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m xi \u001b[38;5;241m=\u001b[39m X_train[i : i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m     12\u001b[0m yi \u001b[38;5;241m=\u001b[39m y_train[i : i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m---> 14\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m compute_loss(yi, y_hat)\n\u001b[0;32m     18\u001b[0m gradients \u001b[38;5;241m=\u001b[39m compute_gradient(xi, yi, y_hat)\n",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(X, theta)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(X, theta):\n\u001b[1;32m----> 5\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m sigmoid(z)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_hat\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (891,8) and (9,) not aligned: 8 (dim 1) != 9 (dim 0)"
     ]
    }
   ],
   "source": [
    "train_accs = []\n",
    "train_losses = []\n",
    "val_accs = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    train_batch_accs = []\n",
    "    train_batch_losses = []\n",
    "    val_batch_accs = []\n",
    "    val_batch_losses = []\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        xi = X_train[i : i + batch_size]\n",
    "        yi = y_train[i : i + batch_size]\n",
    "\n",
    "        y_hat = predict(X, theta)\n",
    "\n",
    "        loss = compute_loss(yi, y_hat)\n",
    "\n",
    "        gradients = compute_gradient(xi, yi, y_hat)\n",
    "\n",
    "        theta = update_theta(theta, gradients, lr)\n",
    "\n",
    "        train_batch_losses.append(loss)\n",
    "        acc = compute_accuracy(xi, yi, theta)\n",
    "        train_batch_accs.append(acc)\n",
    "\n",
    "        y_val_hat = predict(X_val, theta)\n",
    "        val_loss = compute_loss(y_val_hat, y_val)\n",
    "        val_batch_losses.append(val_loss)\n",
    "\n",
    "        val_acc = compute_accuracy(X_val, y_val, theta)\n",
    "        val_batch_accs.append(val_acc)\n",
    "\n",
    "    train_batch_losses = sum(train_batch_losses)/len(train_batch_losses)\n",
    "    train_batch_accs = sum(train_batch_accs)/len(train_batch_accs)\n",
    "    val_batch_accs = sum(val_batch_accs)/len(val_batch_accs)\n",
    "    val_batch_losses = sum(val_batch_losses)/len(val_batch_losses)\n",
    "\n",
    "    train_accs.append(train_batch_accs)\n",
    "    train_losses.append(train_batch_losses)\n",
    "    val_accs.append(val_batch_accs)\n",
    "    val_losses.append(val_batch_losses)\n",
    "\n",
    "    print(f'\\nEPOCH {epoch + 1}:\\tTraining loss: {train_batch_loss:.3f}\\tValidation loss: {val_batch_loss:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
